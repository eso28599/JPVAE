{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 11:28:23.208540: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-26 11:28:23.224592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-26 11:28:23.244678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-26 11:28:23.251781: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-26 11:28:23.268873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-26 11:28:24.329787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import input_pipeline\n",
    "import config\n",
    "from config.MyClfConfig import MyClfConfig\n",
    "from config.ModelConfig import ModelConfig\n",
    "from config.DatasetConfig import CelebADataConfig\n",
    "import data_loading\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config.MyClfConfig.MyClfConfig()\n",
    "cfg.dataset = CelebADataConfig()\n",
    "cfg.model = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.\n",
      "2025-03-26 11:28:50.037268: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/eso18/tensorflow_datasets/celeb_a_dataset_builder/default/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587a9b6a7c1e433982a611da3f916f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e928d63688481f877328337ccb134c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 11:28:52.730417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5337 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create an instance of the dataset builde\n",
    "builder = data_loading.CelebADatasetBuilder(cfg=cfg)\n",
    "\n",
    "# Step 2: Download and prepare dataset (this processes and caches data)\n",
    "builder.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Load dataset as a TensorFlow dataset\n",
    "dataset = builder.as_dataset(split=\"train\")\n",
    "\n",
    "# Step 4: Iterate through the dataset\n",
    "for example in dataset.take(1):\n",
    "    print(example)  # Prints one sample from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils.CelebADataset\n",
    "from utils_data.CelebADataset import CelebADataset \n",
    "# from utils.dataset as dataset\n",
    "# import utils.text as text\n",
    "# import config.DatasetConfig as DatasetConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data import dataset\n",
    "from config.DatasetConfig import CelebADataConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config.DatasetConfig import CelebADataConfig\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import hydra\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra import initialize, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GlobalHydra.instance().is_initialized():\n",
    "    initialize(config_path=\"config\", version_base=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hydra.compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"base_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ConfigStore.instance()\n",
    "# cs.store(group=\"dataset\", name=\"CelebA\", node=CelebADataConfig)\n",
    "cs.store(name=\"base_config\", node=MyClfConfig)\n",
    "\n",
    "cfg = compose(config_name=\"base_config\")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config.MyClfConfig.MyClfConfig()\n",
    "cfg.dataset = CelebADataConfig()\n",
    "cfg.model = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset = dataset.get_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, d_train, val_loader, d_eval = get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = dataset.load_data(cfg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConfigStore' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cs\u001b[38;5;241m.\u001b[39mstore(group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCelebA\u001b[39m\u001b[38;5;124m\"\u001b[39m, node\u001b[38;5;241m=\u001b[39mCelebADataConfig)\n\u001b[1;32m      3\u001b[0m cs\u001b[38;5;241m.\u001b[39mstore(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, node\u001b[38;5;241m=\u001b[39mMyClfConfig)\n\u001b[0;32m----> 4\u001b[0m get_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/clustor2/ma/e/eso18/JPVAE/utils_data/dataset.py:14\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset\u001b[39m(cfg):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     15\u001b[0m         ds \u001b[38;5;241m=\u001b[39m get_dataset_PM(cfg)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mceleba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConfigStore' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "cs = ConfigStore.instance()\n",
    "cs.store(group=\"dataset\", name=\"CelebA\", node=CelebADataConfig)\n",
    "cs.store(name=\"base_config\", node=MyClfConfig)\n",
    "get_dataset = dataset.get_dataset(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_loading' from '/home/clustor2/ma/e/eso18/JPVAE/data_loading.py'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "import utils_data.CelebADataset\n",
    "importlib.reload(utils_data.CelebADataset)\n",
    "import data_loading\n",
    "importlib.reload(data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "missing 1 required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43minput_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_train_set\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/clustor2/ma/e/eso18/JPVAE/input_pipeline.py:26\u001b[0m, in \u001b[0;36mbuild_train_set\u001b[0;34m(batch_size, ds_builder, key)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_train_set\u001b[39m(batch_size, ds_builder, key):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Builds train dataset.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m   train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mds_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m   labs \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mmap(extract_labs)\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;66;03m# labs = jnp.array(list(train_ds.map(extract_labs).batch(10000)))\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: missing 1 required positional argument"
     ]
    }
   ],
   "source": [
    "test = input_pipeline.build_train_set(32, data, random.key(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
